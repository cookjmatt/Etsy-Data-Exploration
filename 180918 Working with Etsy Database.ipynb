{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tues 9/18/18 Working with Etsy Database\n",
    "\n",
    "Tables:\n",
    "\n",
    "listings\n",
    "tags\n",
    "materials\n",
    "styles\n",
    "tags\n",
    "categories\n",
    "category_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import r2_score\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Database definitions and psycopg2 connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'postgres'\n",
    "password = 'jlmlcook'\n",
    "host     = 'localhost'\n",
    "port     = '5432'\n",
    "db_name  = 'etsy'\n",
    "\n",
    "con = None\n",
    "con = psycopg2.connect(user = username, password = password, host = host, port = port, database = db_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting Query Info\n",
    "\n",
    "Items, Tags Per Category:\n",
    "\n",
    "Quilts 74761, 89845\n",
    "\n",
    "Clothing 424994, 486624\n",
    "\n",
    "Jewelry 110937, 189084\n",
    "\n",
    "Shoes 54537, 71316\n",
    "\n",
    "Hat/Hats 36570, 58133 - more reduced = 10539 with count_vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all listing ids for categories 'Hat' or 'Hats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   count\n",
      "0  36570\n"
     ]
    }
   ],
   "source": [
    "#Get relevant listing ids\n",
    "sql_query = None\n",
    "sql_query = \"\"\"\n",
    "SELECT COUNT(DISTINCT listings.listing_id)\n",
    "FROM listings\n",
    "FULL JOIN categories ON listings.listing_id=categories.listing_id\n",
    "WHERE categories.category = 'Hat' or categories.category = 'Hats'\n",
    "\"\"\"\n",
    "\n",
    "print(pd.read_sql_query(sql_query,con))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get relevant listing ids\n",
    "sql_query = None\n",
    "sql_query = \"\"\"\n",
    "SELECT DISTINCT listings.listing_id\n",
    "FROM listings\n",
    "FULL JOIN categories ON listings.listing_id=categories.listing_id\n",
    "WHERE category = 'Hat' OR category = 'Hats'\n",
    "\"\"\"\n",
    "\n",
    "id_list = pd.read_sql_query(sql_query,con)['listing_id'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query the database for all listings, tags, categories, materials, and styles for the listing ids for 'Hat' or 'Hats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['listing_id','price','views','num_favorers','original_creation_tsz','ending_tsz']\n",
    "\n",
    "listings = []\n",
    "tags = []\n",
    "categories = []\n",
    "materials = []\n",
    "styles = []\n",
    "\n",
    "with tqdm(total=len(id_list), file=sys.stdout) as pbar:\n",
    "    #id_list = [100000914]\n",
    "    for i, listing_id in enumerate(id_list):\n",
    "        pbar.set_description('processed: %d' % (1 + i))\n",
    "        pbar.update(1)\n",
    "        # Get listing table info for this ID\n",
    "        sql_query = str('SELECT * FROM listings WHERE listings.listing_id='+str(listing_id))\n",
    "        listings.append(pd.read_sql_query(sql_query,con)[column_names].copy(deep=True))       \n",
    "        #listing = pd.read_sql_query(sql_query,con)[column_names].copy(deep=True)\n",
    "    \n",
    "        # Get tags table info for this ID\n",
    "        sql_query = str('SELECT * FROM tags WHERE tags.listing_id='+str(listing_id))\n",
    "        tags.append(\" \".join(pd.read_sql_query(sql_query,con)['tag']).lower())\n",
    "        #tags = list(set(\" \".join(pd.read_sql_query(sql_query,con)['tag'].tolist()).lower().split()))\n",
    "    \n",
    "        # Get categories table info for this ID\n",
    "        sql_query = str('SELECT * FROM categories WHERE categories.listing_id='+str(listing_id))\n",
    "        categories.append(\" \".join(pd.read_sql_query(sql_query,con)['category']).lower())\n",
    "        #categories = list(set(\" \".join(pd.read_sql_query(sql_query,con)['category'].tolist()).lower().split()))\n",
    "    \n",
    "        # Get materials table info for this ID\n",
    "        sql_query = str('SELECT * FROM materials WHERE materials.listing_id='+str(listing_id))\n",
    "        materials.append(\" \".join(pd.read_sql_query(sql_query,con)['material']).lower())\n",
    "        #materials = list(set(\" \".join(pd.read_sql_query(sql_query,con)['material'].tolist()).lower().split()))\n",
    "    \n",
    "        # Get styles table info for this ID\n",
    "        sql_query = str('SELECT * FROM styles WHERE styles.listing_id='+str(listing_id))\n",
    "        styles.append(\" \".join(pd.read_sql_query(sql_query,con)['style']).lower())\n",
    "        #styles = list(set(\" \".join(pd.read_sql_query(sql_query,con)['style'].tolist()).lower().split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate all listings dataframes into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat(listings, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.shape)\n",
    "print(len(tags))\n",
    "print(len(categories))\n",
    "print(len(materials))\n",
    "print(len(styles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, x in enumerate(styles):\n",
    "    if x:\n",
    "        print(i,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all named features into a single list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = []\n",
    "for i in range(len(tags)):\n",
    "    all_features.append(tags[i]+\" \"+materials[i]+\" \"+styles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features[21]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a countVectorizer for all named features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(binary=True)\n",
    "all_features_vector = vectorizer.fit_transform(all_features)\n",
    "all_features_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save listings dataframe and features to pickle files for faster reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_pickle(\"./listings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_pickle(\"./listings.pkl\")\n",
    "\n",
    "with open('all_features.pickle', 'wb') as handle:\n",
    "    pickle.dump(all_features, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open listings dataframe and features from pickle files for faster reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('listings.pkl', 'rb') as handle:\n",
    "    listings = pickle.load(handle)\n",
    "\n",
    "with open('all_features.pickle', 'rb') as handle:\n",
    "    all_features = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(binary=True)\n",
    "all_features_vector = vectorizer.fit_transform(all_features)\n",
    "all_features_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_matrix = all_features_vector.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vectorizer.transform(['hat', 'crochet', 'baby', 'yarn'])\n",
    "print ('Shape of Sparse Matrix: ', test.shape)\n",
    "print ('Amount of Non-Zero occurences: ', test.nnz)\n",
    "print ('sparsity: %.2f%%' % (100.0 * test.nnz /\n",
    "                             (test.shape[0] * test.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = np.nan_to_num(np.array(listings['price'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(prices).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = all_features_matrix.shape[0]\n",
    "train_fraction = int(n_samples*.8)\n",
    "X_train, y_train = all_features_matrix[:train_fraction], prices[:train_fraction]\n",
    "X_test, y_test = all_features_matrix[train_fraction:], prices[train_fraction:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_samples)\n",
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.Lasso(alpha=0.1)\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.ElasticNet(alpha=0.1)\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
